import tensorflow as tf
import numpy as np
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
# for gpu in gpus:
#     tf.config.experimental.set_memory_growth(device=gpu, enable=True)


gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
tf.config.experimental.set_virtual_device_configuration(
    gpus[0],
    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1200)])

# summary_writer = tf.summary.create_file_writer('./MyOwnMNIST_plot')

# hyper parameters
num_epochs = 4
batch_size = 32
learning_rate = 0.001

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

train_images = np.expand_dims(train_images.astype(np.float32) / 255.0, axis=-1)
test_images = np.expand_dims(test_images.astype(np.float32) / 255.0, axis=-1)

train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))

train_dataset = train_dataset.shuffle(buffer_size=10000)
train_dataset = train_dataset.batch(batch_size)
train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)

# test_dataset = test_dataset.shuffle(buffer_size=5000)
test_dataset = test_dataset.batch(batch_size)
test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)


class CNN(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.conv1 = tf.keras.layers.Conv2D(
            filters=32,
            kernel_size=[5, 5],
            padding='same',
            activation=tf.nn.relu,
            input_shape=(28, 28, 1)
        )
        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)
        self.conv2 = tf.keras.layers.Conv2D(
            filters=64,
            kernel_size=[5, 5],
            padding='same',
            activation=tf.nn.relu
        )
        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)
        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))
        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(units=10, activation='softmax')

    def call(self, inputs):
        x = self.conv1(inputs)
        x = self.pool1(x)  # [batch_size, 14, 14, 32]
        x = self.conv2(x)  # [batch_size, 14, 14, 64]
        x = self.pool2(x)  # [batch_size, 7, 7, 64]
        x = self.flatten(x)  # [batch_size, 7 * 7 * 64]
        x = self.dense1(x)  # [batch_size, 1024]
        output = self.dense2(x)  # [batch_size, 10]
        # output = tf.nn.softmax(x)
        return output


def train():
    # CNN = tf.keras.Sequential([
    #     tf.keras.layers.Conv2D(
    #         filters=32,
    #         kernel_size=[5, 5],
    #         padding='same',
    #         activation=tf.nn.relu,
    #         input_shape=train_images[0].shape
    #     ),
    #     tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2),
    #     tf.keras.layers.Conv2D(
    #         filters=64,
    #         kernel_size=[5, 5],
    #         padding='same',
    #         activation=tf.nn.relu
    #     ),
    #     tf.keras.layers.Conv2D(
    #         filters=64,
    #         kernel_size=[5, 5],
    #         padding='same',
    #         activation=tf.nn.relu
    #     ),
    #     tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2),
    #     tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,)),
    #     tf.keras.layers.Dense(units=1024, activation=tf.nn.relu),
    #     tf.keras.layers.Dense(units=10, activation='softmax')
    # ])

    model = CNN()

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        loss=tf.keras.losses.sparse_categorical_crossentropy,
        metrics=[tf.keras.metrics.sparse_categorical_accuracy]
    )

    checkpoint = tf.train.Checkpoint(MNISTmodel=model)

    model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)

    model.summary()  # 输出模型信息

    checkpoint.save('./myMNISTmodel/model.ckpt')


def test():
    model_reloaded = CNN()
    checkpoint = tf.train.Checkpoint(MNISTmodel=model_reloaded)
    checkpoint.restore(tf.train.latest_checkpoint('./myMNISTmodel'))
    model_reloaded.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        loss=tf.keras.losses.sparse_categorical_crossentropy,
        metrics=[tf.keras.metrics.sparse_categorical_accuracy]
    )
    model_reloaded.evaluate(test_dataset)


if __name__ == '__main__':
    train()
    # test()
